{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BRIDGE: M9.1 Query Decomposition ‚Üí M9.2 Multi-Hop Retrieval\n",
    "\n",
    "**Module**: M9 - Advanced Retrieval Techniques  \n",
    "**Duration**: 8-10 minutes bridge validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose\n",
    "\n",
    "This bridge validates readiness to transition from **M9.1 Query Decomposition** to **M9.2 Multi-Hop Retrieval**. While M9.1 shipped parallel sub-query execution with dependency graphs, it falls short on queries requiring reference-chain following (e.g., \"Find audit findings for CA-2024-001\"). Production impact: 15-25% of queries need multi-hop retrieval, yet current systems achieve only 40% answer quality on these cases‚Äîcosting ‚Çπ25L monthly in manual support work. M9.2 introduces automatic reference extraction, recursive retrieval with stop conditions, and knowledge graph traversal to close this gap."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concepts Covered (Delta)\n",
    "\n",
    "- **Completeness Detection**: Regex-based reference pattern detection (doc IDs, citations) and similarity thresholds to flag incomplete retrievals\n",
    "- **Multi-Hop Readiness**: Validation that M9.1 infrastructure (rate limiting, confidence scoring, parallel execution) meets prerequisites for recursive retrieval\n",
    "- **Reference-Chain Problem**: Quantifying when single-pass retrieval fails and manual intervention becomes necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After Completing This Bridge\n",
    "\n",
    "- ‚úÖ Verify M9.1 query decomposer achieves 95%+ accuracy on test queries\n",
    "- ‚úÖ Confirm dependency graph handles 3+ parallel sub-queries with NetworkX\n",
    "- ‚úÖ Validate rate limiting prevents API throttling (max_concurrent=3)\n",
    "- ‚úÖ Check answer synthesis produces confidence scores ‚â•0.8 for 80% of queries\n",
    "- ‚úÖ Build a completeness detector (Practathon) that identifies queries needing multi-hop retrieval using regex and similarity thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context in Track\n",
    "\n",
    "**Bridge L3.M9.1 ‚Üí L3.M9.2**\n",
    "\n",
    "- **Previous**: M9.1 Query Decomposition (LLM-powered decomposer, dependency graph execution, async executor with rate limiting, synthesis with conflict resolution)\n",
    "- **Current**: Bridge validation notebook (4 readiness checks + practathon)\n",
    "- **Next**: M9.2 Multi-Hop Retrieval (automatic reference extraction, recursive retrieval with 2-5 hop depth, BFS/DFS graph traversal optimization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Run Locally\n",
    "\n",
    "**Windows (PowerShell)**:\n",
    "```powershell\n",
    "powershell -c \"$env:PYTHONPATH='$PWD'; jupyter notebook\"\n",
    "```\n",
    "\n",
    "**macOS/Linux**:\n",
    "```bash\n",
    "PYTHONPATH=$PWD jupyter notebook\n",
    "```\n",
    "\n",
    "**Optional Dependencies**: `pip install networkx` (notebook includes offline fallbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 1: Recap - What M9.1 Shipped\n",
    "\n",
    "M9.1 (Query Decomposition) delivered four key accomplishments:\n",
    "\n",
    "1. **LLM-Powered Query Decomposer**\n",
    "   - Achieved 95%+ accuracy on test queries\n",
    "   - Breaks complex queries into executable sub-queries\n",
    "\n",
    "2. **NetworkX-Based Dependency Graph Execution**\n",
    "   - 60% latency reduction through parallel execution\n",
    "   - Handles complex query dependencies\n",
    "\n",
    "3. **Production-Ready Async Executor**\n",
    "   - Rate limiting to prevent API throttling\n",
    "   - Async execution with max_concurrent controls\n",
    "\n",
    "4. **Synthesis System with Conflict Resolution**\n",
    "   - Confidence scoring for answer quality\n",
    "   - Automatic conflict resolution between sub-query results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify M9.1 Capabilities\n",
    "\n",
    "Summarize the four shipped capabilities from M9.1 and confirm their deployment status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# M9.1 Capabilities Summary\n",
    "m9_1_capabilities = {\n",
    "    \"query_decomposer\": {\"accuracy\": 0.95, \"status\": \"shipped\"},\n",
    "    \"dependency_graph\": {\"latency_reduction\": 0.60, \"status\": \"shipped\"},\n",
    "    \"async_executor\": {\"rate_limiting\": True, \"status\": \"shipped\"},\n",
    "    \"synthesis_system\": {\"conflict_resolution\": True, \"status\": \"shipped\"}\n",
    "}\n",
    "\n",
    "print(\"‚úÖ M9.1 Query Decomposition - Shipped Capabilities:\")\n",
    "for capability, details in m9_1_capabilities.items():\n",
    "    print(f\"  ‚Ä¢ {capability}: {details['status']}\")\n",
    "\n",
    "# Expected:\n",
    "# ‚úÖ M9.1 Query Decomposition - Shipped Capabilities:\n",
    "#   ‚Ä¢ query_decomposer: shipped\n",
    "#   ‚Ä¢ dependency_graph: shipped\n",
    "#   ‚Ä¢ async_executor: shipped\n",
    "#   ‚Ä¢ synthesis_system: shipped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 2: Readiness Check #1 - Query Decomposer Accuracy\n",
    "\n",
    "**Requirement**: Query decomposer achieving 95%+ accuracy on test queries\n",
    "\n",
    "**Validation**: Run decomposer on sample complex queries and measure accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Query Decomposer Accuracy\n",
    "\n",
    "Validate that the M9.1 decomposer meets the 95%+ accuracy threshold on complex multi-part queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Readiness Check #1: Query Decomposer Accuracy ‚â•95%\n",
    "\n",
    "test_queries = [\n",
    "    \"Find audit findings for CA-2024-001 and summarize compliance gaps\",\n",
    "    \"Compare Q3 and Q4 revenue across all regions\",\n",
    "    \"What are the dependencies between Project Alpha and Project Beta?\"\n",
    "]\n",
    "\n",
    "# Stub: Query decomposer validation\n",
    "def validate_query_decomposer(queries):\n",
    "    \"\"\"Check if decomposer achieves 95%+ accuracy\"\"\"\n",
    "    # In production: would call actual M9.1 decomposer\n",
    "    print(\"‚ö†Ô∏è Skipping (no M9.1 decomposer service)\")\n",
    "    return {\"accuracy\": None, \"status\": \"not_tested\"}\n",
    "\n",
    "result = validate_query_decomposer(test_queries)\n",
    "print(f\"Status: {result['status']}\")\n",
    "\n",
    "# Expected:\n",
    "# ‚ö†Ô∏è Skipping (no M9.1 decomposer service)\n",
    "# Status: not_tested\n",
    "# (In production: accuracy ‚â• 0.95 ‚Üí PASS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 3: Readiness Check #2 - Dependency Graph Parallel Execution\n",
    "\n",
    "**Requirement**: Dependency graph execution handling 3+ parallel sub-queries\n",
    "\n",
    "**Validation**: Test parallel execution of independent sub-queries using NetworkX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify Parallel Sub-Query Execution\n",
    "\n",
    "Create a test dependency graph with 3+ parallel branches to confirm M9.1 can execute independent sub-queries concurrently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Readiness Check #2: Dependency Graph Handling 3+ Parallel Sub-Queries\n",
    "\n",
    "try:\n",
    "    import networkx as nx\n",
    "    \n",
    "    # Create test dependency graph with 3+ parallel branches\n",
    "    G = nx.DiGraph()\n",
    "    G.add_edges_from([(\"root\", \"sq1\"), (\"root\", \"sq2\"), (\"root\", \"sq3\")])\n",
    "    \n",
    "    parallel_count = len([n for n in G.successors(\"root\")])\n",
    "    \n",
    "    print(f\"‚úÖ NetworkX available\")\n",
    "    print(f\"Parallel sub-queries: {parallel_count}\")\n",
    "    print(f\"Status: {'PASS' if parallel_count >= 3 else 'FAIL'}\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è Skipping (NetworkX not installed)\")\n",
    "\n",
    "# Expected:\n",
    "# ‚úÖ NetworkX available\n",
    "# Parallel sub-queries: 3\n",
    "# Status: PASS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 4: Readiness Check #3 - Rate Limiting\n",
    "\n",
    "**Requirement**: Rate limiting preventing API throttling (max_concurrent=3)\n",
    "\n",
    "**Validation**: Verify async executor respects concurrency limits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Rate Limiting Controls\n",
    "\n",
    "Run 10 concurrent tasks with a max_concurrent=3 semaphore to ensure the executor never exceeds the limit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Readiness Check #3: Rate Limiting (max_concurrent=3)\n",
    "\n",
    "import asyncio\n",
    "from asyncio import Semaphore\n",
    "\n",
    "async def test_rate_limiting():\n",
    "    \"\"\"Validate rate limiting with max_concurrent=3\"\"\"\n",
    "    max_concurrent = 3\n",
    "    semaphore = Semaphore(max_concurrent)\n",
    "    active_count = 0\n",
    "    peak_concurrent = 0\n",
    "    \n",
    "    async def limited_task(task_id):\n",
    "        nonlocal active_count, peak_concurrent\n",
    "        async with semaphore:\n",
    "            active_count += 1\n",
    "            peak_concurrent = max(peak_concurrent, active_count)\n",
    "            await asyncio.sleep(0.01)  # Simulate work\n",
    "            active_count -= 1\n",
    "    \n",
    "    tasks = [limited_task(i) for i in range(10)]\n",
    "    await asyncio.gather(*tasks)\n",
    "    \n",
    "    print(f\"‚úÖ Rate limiting validated\")\n",
    "    print(f\"Max concurrent setting: {max_concurrent}\")\n",
    "    print(f\"Peak concurrent observed: {peak_concurrent}\")\n",
    "    print(f\"Status: {'PASS' if peak_concurrent <= max_concurrent else 'FAIL'}\")\n",
    "\n",
    "await test_rate_limiting()\n",
    "\n",
    "# Expected:\n",
    "# ‚úÖ Rate limiting validated\n",
    "# Max concurrent setting: 3\n",
    "# Peak concurrent observed: 3\n",
    "# Status: PASS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 5: Readiness Check #4 - Answer Synthesis Confidence Scoring\n",
    "\n",
    "**Requirement**: Answer synthesis producing confidence scores ‚â•0.8 for 80% of queries\n",
    "\n",
    "**Validation**: Test synthesis system with sample sub-query results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Confidence Score Distribution\n",
    "\n",
    "Analyze simulated sub-query results to verify that at least 80% achieve high confidence (‚â•0.8) thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Readiness Check #4: Confidence Scoring ‚â•0.8 for 80% of Queries\n",
    "\n",
    "# Sample sub-query results with simulated confidence scores\n",
    "sample_results = [\n",
    "    {\"query\": \"Q1\", \"answer\": \"...\", \"confidence\": 0.92},\n",
    "    {\"query\": \"Q2\", \"answer\": \"...\", \"confidence\": 0.85},\n",
    "    {\"query\": \"Q3\", \"answer\": \"...\", \"confidence\": 0.78},\n",
    "    {\"query\": \"Q4\", \"answer\": \"...\", \"confidence\": 0.88},\n",
    "    {\"query\": \"Q5\", \"answer\": \"...\", \"confidence\": 0.91}\n",
    "]\n",
    "\n",
    "high_confidence = [r for r in sample_results if r[\"confidence\"] >= 0.8]\n",
    "percentage = len(high_confidence) / len(sample_results)\n",
    "\n",
    "print(f\"Total queries: {len(sample_results)}\")\n",
    "print(f\"High confidence (‚â•0.8): {len(high_confidence)}\")\n",
    "print(f\"Percentage: {percentage:.0%}\")\n",
    "print(f\"Status: {'PASS' if percentage >= 0.8 else 'FAIL'}\")\n",
    "\n",
    "# Expected:\n",
    "# Total queries: 5\n",
    "# High confidence (‚â•0.8): 4\n",
    "# Percentage: 80%\n",
    "# Status: PASS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 6: Practathon Checkpoint - Completeness Detector\n",
    "\n",
    "**Exercise**: Build a completeness detector (30 minutes target)\n",
    "\n",
    "**Goal**: Identify queries needing multi-hop retrieval\n",
    "\n",
    "**Tasks**:\n",
    "1. Detect reference patterns (regex for reference #, doc ID, document codes)\n",
    "2. Analyze similarity scores (flag <0.75 as potentially incomplete)\n",
    "3. Calculate decision thresholds with 85%+ precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Reference Pattern Detector\n",
    "\n",
    "Use regex to identify document references (e.g., \"CA-2024-001\", \"reference #ABC\") and combine with similarity thresholds to flag queries needing multi-hop retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practathon: Completeness Detector Stub\n",
    "\n",
    "import re\n",
    "\n",
    "def detect_reference_patterns(text):\n",
    "    \"\"\"Detect reference patterns in query/document text\"\"\"\n",
    "    patterns = [\n",
    "        r'reference\\s*#\\s*\\w+',           # \"reference #ABC123\"\n",
    "        r'\\b[A-Z]{2}-\\d{4}-\\d{3}\\b',      # \"CA-2024-001\"\n",
    "        r'\\bdoc(?:ument)?\\s+ID\\s*\\w+',    # \"doc ID XYZ\"\n",
    "    ]\n",
    "    \n",
    "    matches = []\n",
    "    for pattern in patterns:\n",
    "        matches.extend(re.findall(pattern, text, re.IGNORECASE))\n",
    "    \n",
    "    return len(matches) > 0, matches\n",
    "\n",
    "def needs_multi_hop(query, similarity_score):\n",
    "    \"\"\"Determine if query needs multi-hop retrieval\"\"\"\n",
    "    has_refs, refs = detect_reference_patterns(query)\n",
    "    low_similarity = similarity_score < 0.75\n",
    "    \n",
    "    return has_refs or low_similarity\n",
    "\n",
    "# Test\n",
    "test_cases = [\n",
    "    (\"Find audit findings for CA-2024-001\", 0.82),\n",
    "    (\"What is our Q3 revenue?\", 0.68),\n",
    "]\n",
    "\n",
    "for query, score in test_cases:\n",
    "    needs_hop = needs_multi_hop(query, score)\n",
    "    print(f\"Query: {query[:40]}... | Score: {score} | Multi-hop: {needs_hop}\")\n",
    "\n",
    "# Expected:\n",
    "# Query: Find audit findings for CA-2024-001... | Score: 0.82 | Multi-hop: True\n",
    "# Query: What is our Q3 revenue?... | Score: 0.68 | Multi-hop: True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 7: Call-Forward - What M9.2 Will Introduce\n",
    "\n",
    "**Problem**: Reference-chain limitations in single-pass retrieval\n",
    "\n",
    "**Impact**: \n",
    "- 15-25% of queries require reference following\n",
    "- Current systems achieve only 40% answer quality on these cases\n",
    "- **Cost**: 1,000 reference queries/day √ó 10 min manual work = ‚Çπ25L monthly support expense\n",
    "\n",
    "**M9.2 Multi-Hop Retrieval** will introduce:\n",
    "\n",
    "1. **Automatic Reference Extraction**\n",
    "   - Parse document references (IDs, citations, cross-references)\n",
    "   - Extract linked entities from retrieved documents\n",
    "\n",
    "2. **Recursive Retrieval with Stop Conditions**\n",
    "   - 2-5 hop depth for reference chain following\n",
    "   - Prevent infinite loops with cycle detection\n",
    "   - Early termination when completeness threshold reached\n",
    "\n",
    "3. **Knowledge Graph Traversal Optimization**\n",
    "   - BFS (Breadth-First Search) for broad context\n",
    "   - DFS (Depth-First Search) for deep reference chains\n",
    "   - Hybrid strategies for complex query patterns\n",
    "\n",
    "**Next Steps**: Proceed to M9.2 Concept video to learn multi-hop retrieval implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preview M9.2 Capabilities\n",
    "\n",
    "Summarize the three major capabilities M9.2 will introduce to solve the reference-chain problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# M9.2 Preview: Key Capabilities\n",
    "\n",
    "m9_2_capabilities = {\n",
    "    \"reference_extraction\": {\"auto_parse\": True, \"status\": \"upcoming\"},\n",
    "    \"recursive_retrieval\": {\"max_depth\": 5, \"status\": \"upcoming\"},\n",
    "    \"graph_traversal\": {\"algorithms\": [\"BFS\", \"DFS\"], \"status\": \"upcoming\"},\n",
    "}\n",
    "\n",
    "print(\"üöÄ M9.2 Multi-Hop Retrieval - Upcoming Capabilities:\")\n",
    "for capability, details in m9_2_capabilities.items():\n",
    "    print(f\"  ‚Ä¢ {capability}: {details['status']}\")\n",
    "\n",
    "# Expected:\n",
    "# üöÄ M9.2 Multi-Hop Retrieval - Upcoming Capabilities:\n",
    "#   ‚Ä¢ reference_extraction: upcoming\n",
    "#   ‚Ä¢ recursive_retrieval: upcoming\n",
    "#   ‚Ä¢ graph_traversal: upcoming"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}